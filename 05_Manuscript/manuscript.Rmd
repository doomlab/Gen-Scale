---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  One or two sentences to put the results into a more **general context**.
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"


floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
bibliography: references.bib
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

Introduction

Example citation: [@dplyr]

[@rosseel2012]

Intro - awareness of death, especially in light of COVID.

Various existential philosophers and psychologists have proposed ways in which we deal with the awareness of death and the anxiety this awareness often causes. Psychoanalyst Erik Erikson (1950) proposed that during mid-life one becomes acutely aware of their oncoming death and is motivated to care for things which will outlast themselves. He called this act of caring generativity. In *The Denial of Death* (1973), philosopher Ernest Becker posits that humans undertake immortality projects to curb their sense of vulnerability to death. Similarly, psychiatrist Robert Jay Lifton (1979), a mentee of Erikson, described the awareness of death as being ever present and motivating us to create symbols thereby allowing ourselves to imagine us as symbolically immortalized. Existential psychiatrist, Irvin Yalom (2008) notes that many of his clients experiencing anxiety about their death take comfort in “rippling”, the idea that one’s lasting effects on the world will ripple out and influence the world after they have died.

Although these thinkers use different terminology, there are several common themes among their ideas. (1) Our physical death is an inevitability, and we often find our awareness of its inevitability to be aversive: that is, it can cause angst, death-anxiety, despair, being-towards-death, terror, and so on. However, (2) we take comfort in the idea that other, non-physical parts of us continue to exist indefinitely after our biological death, through mechanisms such as the heroic archetype and symbolic self. (3) Finally, we can take action to promote these non-physical aspects of the self, such as through search for meaning, immortality project, care, generativity, rippling.

Sense of symbolic immortality was originally theorized by Lifton (1979), who thought that awareness of death drives a fundamental human need to "develop a sense of continuity and lastingness" beyond the lifespan (quote from Drolet 1990). Humans as meaning-seeking creatures.

Lifton (1979) proposed five modes of experience or ways of achieving symbolic immortality: The biological (or biosocial) mode in which one lives on through their genetic and socio-cultural progeny, the creative mode in which one’s accomplishments and contribution outlast oneself, the natural mode in which one feels they are a part of the broader universe, the spiritual mode in which one seeks to transcend the physical realm to a higher spiritual realm beyond death, and the mode of experiential transcendence in which one experiences a phenomenological state of flow. The latter (experiential transcendence) must occur in the context of one of the other four to really be considered transcendent, but it is thought to have a great capacity to bring about personal change.

Sense of psychological death?

Though some denial of death is thought to be universal, acceptance of the reality of death can drive what Drolet (1990) refers to as personal and collective creativity, or what Erikson referred to as generativity. Erikson's theory and generativity.

Current measures of generativity are more about domains of generativity, actions, trait rather than underlying motives. Loyola Generativity Scale and the authors' understanding of the dimensions of generativity. Underlying motivation of generativity thought to be related to a motive to expand the sense of self beyond the lifetime (Kotre 1984), especially in light of the fear of death. McAdams and de St. Aubin (1992) indeed found symbolic immortality to be one of five themes across content analysis of autobiographical episodes.

Somewhat loss of religiosity in the West that may have been a way of coping/finding a sense of immortality in the past. Likely this may have fallen under the umbrella of the spiritual mode of immortality, and for many a literal belief in life after death. Perhaps many now would benefit more from a sense of collective, social, or creative immortality. (some citations here if I keep this paragraph)

Claims of how we suppress death-anxiety have been investigated experimentally, primarily through the paradigm of Terror Management Theory (TMT). Based on the theories of Ernest Becker, TMT posits that human awareness of death is always present to some degree. This awareness of our inevitable death, coupled with a strong aversion to thoughts of death, causes terror and is pushed out of our consciousness by our creation of meaning systems (CITATION). TMT refers to a person's awareness of death as mortality salience (MS). The MS hypothesis of TMT posits than an increase in one's awareness of death causes an increase in compensatory behaviors to lower their death anxiety, either by distracting from the awareness of death or by the promotion of meaningful cultural worldviews. A meta-analysis of 277 experiments has found mortality salience to have moderate effects (*r* = 0.35; Burke, Martens & Faucher, 2010). TMT literature has found three consistent buffers of our awareness of death: self-esteem, interpersonal relationships, and cultural worldview (CITATION, unless it's the same as above, in which case make that clear).

TMT research is conducted in two paradigms. In the MS paradigm, a participant’s increased awareness of death causes an increase in compensatory buffers. In the death-thought accessibility paradigm, experimentally decreasing participants’ buffers, such as lowering self-esteem or challenging their worldview beliefs, causes (CHECK THIS AND CITE ACTUAL STUDIES) an increase in their awareness of death. Together, these experiments provide convincing evidence of these of suppressing awareness of death and death anxiety.

It is assumed that such changes in attitude and behavior suppress thoughts of death by giving a sense of existential immortality; however, to our knowledge no researchers have attempted to assess subjective feelings of immortality. This missing literature may in part be because of a lack of a viable measure of existential immortality. We view this dearth as a large gap in the literature and methodology. Two attempts have been made to develop such a measurement: Drolet's (1990) Sense of Symbolic Immortality Scale and Mathews and Kling (1988) measure of symbolic immortality, based on an original questionnaire by Mathews and Mister (1987).

NOTE\*\*\* can't get access to the Mathews and Kling article but it seems mostly related to prosocial behavior for nonprofit stuff - should we just focus on the original Mathews and Mister article? Some other articles I found use the Mathews and Kling version though. <https://journals.sagepub.com/doi/abs/10.1177/089976408801700202?download=true&journalCode=nvsa>

Drolet (1990) developed the Sense of Symbolic Immortality Scale based on Robert J. Lifton’s theory of symbolic immortality and its five modes of experience. Drolet studied 136 adults, ages 18-30 and 30-40, and hypothesized that those in their 30's (established adults) would have a greater sense of symbolic immortality than the young adults (18-30). The measure is inherently subjective, not only by the nature of self-report, but in that the scale seeks to measure what a person *believes* and how they *feel* about these subjects. The scale as a whole had a high internal consistency (alpha = .91) and test-retest reliability was r = .97. Internal consistency of subscales for the five theoretical modes of immortality was mixed. Of the five, spiritual immortality was the most distinct from the scale as a whole and the other subscales. (Note that this seems relevant to what we found in our own scale development. For more in the Discussion later on.) Factor analysis showed three factors, mapping onto biosocial, creative, and spiritual. The transcendent and natural items may be related to biosocial.

Moving beyond the scale development itself (still Drolet 1990), SSI correlated negatively with death anxiety (Templer's Death Anxiety Scale) and had a strong (r = .84) positive relationship with purpose in life (Maholick's Purpose in Life Test). In interpreting the very strong correlation, the author suggests that SSI is a broader construct than Purpose in Life and the scale itself may be less prone to social desirability effects than the PIL, although this had not been directly tested. Age group was also related, with established adults having a higher SSI, particularly in the biosocial and creative domains.

We see multiple issues with using the Symbolic Immortality Scale. First, the study was underpowered, conducting exploratory factor analysis of 67 items using a sample of 136. Second, the scale was developed in French, and we do not take for granted the psychometric properties of a translated version. Third and most fundamentally, the scale has poor face validity and appears to measure the constructs theorized to symbolically immortalize rather than a sense of symbolic immortality directly. For example, the scale includes items such as “My sex life contributes greatly to my well-being”, “Intimate relationships scare me”, and “I am sure of who I am." Although related to the constructs (such as interpersonal relationships and self-esteem) which theoretically help cope with death, it is unclear how these items represent the construct of symbolic immortality itself.

Mathews and Mister (1987) also developed a scale involving symbolic immortality, sensation seeking, and psychic numbness. Some studies have used a revised version of the scale by Mathews and Kling (1988), who adapted it for a study on prosocial behavior in the context of nonprofit volunteer motivation. Mathews and Mister's study included 400 adults. Experiential transcendence was operationalized as something like Zuckerman's (1979) sensation seeking, which may not fully capture the original intent (the experience of losing oneself). Items were forced into five factors, and the five factors largely aligned with Lifton's constructs. Although internal consistency was at least acceptable for each factor, goodness of fit statistics are not reported. The items themselves seem to have more face validity than the scale by Drolet, but some factors seem more behavioral and specific: pertaining to one's religiosity or biological children, whereas Lifton's theory allows for a broader interpretation of these dimensions. The Nature and Creative factors seems most useful and theoretically aligned with Lifton.

The goal of the present research is to develop a scale that more directly measures one’s sense of existential immortality in a way more generally applicable regardless of a person's religious beliefs and parental status. We have attempted to use current best practices for scale development.

# Method

## Participants

## Material

## Procedure

## Data analysis

# Results

```{r libraries}
library(rio)
library(dplyr)
set.seed(8943)
library(mice)

## args: dat: Dataframe of scale values, with each row being a participant and each column being a scale question
## args: rt: vector of response time/page time for each participant
## args: min: minimum value of scale
## args: max: maximum value of scale
## args: partno: vector of corresponding participant numbers
## args: clicks: click count column, outputted by qualtrics
## args: manvec: vector of manipulation check question responses
## args: mancor: correct answer of manipulation check
## args: char: number of characters on the page

SAD <- function(dat, #data frame of only scale values
               rt = NULL, #column name for page timing
               min = 1, #lower end of scale points
               max = 7, #upper end of scale points
               partno, #participant number so you can merge and identify outliers
               click = NULL, #column of click counts
               manvec = NULL, #column of manipulation check
               mancor = NULL, #answer to the manipulation check
               char = NULL){ #number of characters on the page
  
  ##make sure the data provided is a data frame
  dat = as.data.frame(dat)
  
  ####number of scale options used####
  OptUse = function(x){
    length(table(as.vector(as.matrix(unname(x)))))
  }
  numOpt = apply(dat,1,OptUse)
  numOpt = as.numeric(numOpt)
  nsim = length(numOpt)
  badScaleCheck = rep(NA, length(numOpt))
  for(i in 1:nsim){
    ##more than half of the options
    optionhalf = length(min:max)/2+1
    if(numOpt[i] >= optionhalf){
      badScaleCheck[i] = 1
    } else { badScaleCheck[i] = 0 }
  }
  badScaleCheck = as.numeric(badScaleCheck)
  
  
  ####response/page time####
  if (!is.null(rt)){
    rt = as.numeric(unlist(rt))
    
    ourchar = char
    meanchar = 987
    sdchar = 118
    upperchar = meanchar + 2*sdchar
    cutoffChar = ourchar / upperchar * 60
    badChar = rep(NA, length(rt))
    nsim = length(badChar)
    for(i in 1:nsim){
      if(!is.na(rt[i])){
        if(rt[i] < cutoffChar){
          badChar[i] = 1
        } else{
          badChar[i] = 0
        }
      } else { badChar[i] = NA}
    }
    badChar = as.numeric(badChar)
  } else { badChar = rep(NA, nrow(dat))}
  
  ####click count check####
  if(!is.null(click)){
    click = as.numeric(unlist(click))
    totalexp = apply(dat,1, function(x){sum(!is.na(x))})
    nsim = length(click)
    badClick = rep(NA, length(click))
    for(i in 1:nsim){
      if(!is.na(click[i])){
        if(click[i] >= totalexp[i]){
          badClick[i] = 0
        } else{
          badClick[i] = 1
        }
      } else{ badClick[i] = NA}
    }
    badClick = as.numeric(badClick)
  } else { badClick = rep(NA, nrow(dat))}
  
  ####manipulation check question manip####
  if(!is.null(manvec)){
    manvec = as.numeric(unlist(manvec))
    nsim = length(manvec)
    badMC = rep(NA, nrow(dat))
    for(i in 1:nsim){
      if(!is.na(manvec[i])){ 
        if(manvec[i] == mancor) { badMC[i] = 0 } else { badMC[i] = 1}} else { badMC[i] = 1}
    }
    badMC = as.numeric(badMC)
  } else { badMC = rep(NA, nrow(dat))}
  
  ####Distribution Testing####
  uniform = rep(NA,nrow(dat))
  normal = rep(NA, nrow(dat))
  dist = rep(NA, nrow(dat))
  nsim = nrow(dat)
  for(i in 1:nsim){
    temprow = as.numeric(unname(dat[i,])) 
    utable = matrix(0, nrow = 1, ncol = length(min:max))
    for(x in min:max) {
      utable[x] = length(temprow[ temprow == x])
    }
    uniformest = chisq.test(utable,
                            rescale.p = T,
                            simulate.p.value = T)
    ##test normal distribution
    ##first convert to z score
    ztest = scale(temprow)
    ##then figure out how much of the data is binned for SDs
    ztable = matrix(0, nrow = 1, ncol = 6)
    ztable[1] = length(ztest[ ztest <= -2 ])  
    ztable[2] = length(ztest[ ztest > -2 & ztest <= -1  ])
    ztable[3] = length(ztest[ ztest > -1 & ztest <= 0 ])
    ztable[4] = length(ztest[ ztest > 0 & ztest <= 1 ])
    ztable[5] = length(ztest[ ztest > 1 & ztest <= 2 ])
    ztable[6] = length(ztest[ ztest > 2 ])
    znormal = c(0.0228, 0.1359, 0.3413, 0.3413, 0.1359, 0.0228)
    normalest = chisq.test(ztable,
                           p = znormal*sum(ztable),
                           rescale.p = T,
                           simulate.p.value = T)
    ##output return chi square values
    uniform[i] = uniformest$statistic
    normal[i] = normalest$statistic
    ##if uniform < normal
    if(uniformest$statistic < normalest$statistic)
    {
      ##if more than 1 option
      if (numOpt[i]>1)
      {
        dist[i] = 0 ##uniform is better
      } else { ##handles when people only pick one thing
        dist[i] = 2
      }
    }
    ##if uniform >= normal
    if(uniformest$statistic >= normalest$statistic)
    {
      ##if more than 1 option
      if (numOpt[i]>1)
      {
        dist[i] = 1 ##normal is better
      } else { ##handles when people only pick one thing
        dist[i] = 2
      }
      
    }
    #0 means uniform fits better
    #1 means normal fits better
    #2 means only chose one scale option
  }## end of for loop
  
  ####distribution coding####
  badDist = rep(NA, nsim)
  for(i in 1:nsim){
    if(dist[i] == 0){
      badDist[i] = 1
    } 
    if (dist[i] == 1){
      badDist[i] = 0
    } 
    if (dist[i] == 2) {
      badDist[i] = 0
    }
  }
  badDist = as.numeric(badDist)
  
  ####total up####
  badDF = cbind.data.frame(badChar, badClick, badDist, badScaleCheck, badMC)
  badDF$badTotal = apply(badDF, 1, sum, na.rm = T)
  badDF$participant = partno
  
  return(badDF)
  
} #end function

percentmiss <- function(x){ sum(is.na(x))/length(x) *100 }
```

```{r load-data, eval = T}
sona <- import("../03_Data/sona_data_deidentify.csv") %>% 
  mutate(where = "sona")
mturk <- import("../03_Data/mturk_data_deidentify.csv") %>% 
  mutate(where = "mturk")
```

## Data Screening

```{r screen-sona-accuracy-out, eval = F}
# Accuracy ----
summary(sona %>% 
          select(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20))
# everything is within the expected range

apply(sona %>% 
          select(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20), 
      2, mean, na.rm = TRUE)
apply(sona %>% 
          select(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20), 
      2, sd, na.rm = TRUE)
# check reverse items? Q2_21? 

# Missing ----

# rows
missing <- apply(sona %>% 
          select(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20), 
          1, 
          percentmiss) 
table(missing)
replacepeople <- subset(sona, missing <= 5)
dontpeople <- subset(sona, missing > 5)

# columns
missingcol <- apply(replacepeople %>% 
                      select(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20), 
                    2, 
                    percentmiss)
table(missingcol) # all replaceable

replacecolumn <- replacepeople %>% 
  select(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20)
dontcolumn <- replacepeople %>% 
  select(-c(Q2_1:Q2_21, Q4_1:Q4_20, Q5_1:Q5_20))

# replacing those with <= 5% missing by multiple imputation
tempnomiss <- mice(replacecolumn)
nomiss <- complete(tempnomiss, 1)
summary(nomiss)

# putting data back together
# excluding participants with > 5% missing (7 total)
allcolumns <- cbind(dontcolumn, nomiss)
summary(allcolumns)
write.csv(allcolumns, "../03_Data/sona_data_replaced.csv", row.names = F)
```

```{r screen-sona-SAD}
# SAD 
nomissing <- import("../03_Data/sona_data_replaced.csv")

# Block 1
page1 <- SAD(dat = nomissing %>% 
               select(Q2_1:Q2_21),
    rt = nomissing$`Q10_Page Submit`,
    min = 1, 
    max = 5, 
    partno = nomissing$ResponseId, 
    click = nomissing$`Q10_Click Count`, 
    manvec = nomissing$Q2_21, 
    mancor = 1, 
    char = 1626)
write.csv(page1, "../03_Data/sona_page1_sad.csv", row.names = F)

# Block 2
page2 <- SAD(dat = nomissing %>% 
               select(Q4_1:Q4_20), 
            rt = nomissing$`Q11_Page Submit`,
            min = 1, 
            max = 5, 
            partno = nomissing$ResponseId, 
            click = nomissing$`Q11_Click Count`, 
            manvec = nomissing$Q4_20, 
            mancor = 4, 
            char = 1491)
write.csv(page2, "../03_Data/sona_page2_sad.csv", row.names = F)

# Block 3
page3 <- SAD(dat = nomissing %>% 
               select(Q5_1:Q5_20), 
            rt = nomissing$`Q12_Page Submit`,
            min = 1, 
            max = 5, 
            partno = nomissing$ResponseId, 
            click = nomissing$`Q12_Click Count`, 
            manvec = nomissing$Q5_16, 
            mancor = 3, 
            char = 1496)
write.csv(page3, "../03_Data/sona_page3_sad.csv", row.names = F)

# Total
nomissing$totalbad <- page1$badTotal + page2$badTotal + page3$badTotal

nomissing$totalbadUP = 
  page1$badChar + page1$badClick + page1$badMC + 
  page2$badChar + page2$badClick + page2$badMC + 
  page3$badChar + page3$badClick + page3$badMC
table(nomissing$totalbadUP)
nolowqual = subset(nomissing, totalbadUP < 4)
##B&S say 2/5 which is 40%, so 40% of the 9 total is 3.6 or 4 or more

# Outliers ----------------------------------------------------------------

mahal = mahalanobis(nolowqual[ , 37:97], 
                    colMeans(nolowqual[ , 37:97], na.rm = TRUE),
                    cov(nolowqual[ , 37:97], use="pairwise.complete.obs"))

cutoff = qchisq(1 - .001,ncol(nolowqual[ , 37:97]))
ncol(nolowqual[ , 37:97]) #df 61
cutoff #cutoff 100.8879

summary(mahal < cutoff)
mahal[mahal > cutoff]

noout = subset(nolowqual, mahal < cutoff)
#42 participants excluded as outliers

# Assumptions -------------------------------------------------------------

# Linearity #
random = rchisq(nrow(noout[ , 37:97]), 7) 
fake = lm(random~., data=noout[ , 37:97])

standardized = rstudent(fake)
{qqnorm(standardized)
  abline(0,1)}
#seems okay

# Normality #
hist(standardized, breaks=15)
#a little skewed but mostly centered on 0 and between -2 and 2 so okay

# Homog/s #
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
  abline(0,0)
  abline(v = 0)}
#some homogeneity issues but we'll accept it

write.csv(noout, file = "sona_data_screened.csv", row.names = F)
library(beepr)
beep(sound = 5)

# > nrow(master)
# [1] 564
# > nrow(nomissing)
# [1] 557
# > nrow(nolowqual)
# [1] 507
# > nrow(noout)
# [1] 464





sona_screen_1 <- SAD(
  dat = sona %>% 
    select(Q2_1:Q2_21, `Q10_Page Submit`, `Q10_Click Count`),
  rt = "Q10_Page Submit",
  min = 1,
  max = 5, 
  partno = "ResponseId",
  clicks = "Q10_Click Count",
  
  
  
)


## args: dat: Dataframe of scale values, with each row being a participant and each column being a scale question
## args: rt: vector of response time/page time for each participant
## args: min: minimum value of scale
## args: max: maximum value of scale
## args: partno: vector of corresponding participant numbers
## args: clicks: click count column, outputted by qualtrics
## args: manvec: vector of manipulation check question responses
## args: mancor: correct answer of manipulation check
## args: char: number of characters on the page
```


# Discussion

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
